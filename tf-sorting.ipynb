{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Seq2Seq Model with Attention in Sorting Problems\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dummy(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "input_size = 30\n",
    "max_time = 30\n",
    "embedding_size = 10\n",
    "num_units = embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_batch(batch_size, seq_len, max_time, input_size=10):\n",
    "    data = np.zeros((batch_size, max_time), dtype='int32')\n",
    "    data[:,:seq_len] = np.random.randint(1, input_size+1, (batch_size, seq_len))\n",
    "    labels = np.zeros((batch_size, max_time), dtype='int32')\n",
    "    labels[:,:seq_len] = np.sort(data[:, :seq_len])\n",
    "    \n",
    "    # time major\n",
    "    return data.T, labels.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialization():\n",
    "    model = Dummy()\n",
    "    model.encoder_inputs = tf.placeholder('int32', [max_time, None], name='encoder_inputs')\n",
    "    model.targets = tf.placeholder('int32', [max_time, None], name='target')\n",
    "    model.decoder_inputs = tf.concat([tf.fill([1, tf.shape(model.targets)[1]], 0), model.targets[:-1,:]], 0)\n",
    "    \n",
    "    model.source_sequence_lengths = tf.placeholder('int32', [None], name='source_sequence_lengths')\n",
    "    model.target_sequence_lengths = tf.placeholder('int32', [None], name='target_sequence_lengths')\n",
    "    \n",
    "    model.learning_rate = tf.placeholder('float32', [], name='learning_rate')\n",
    "    model.max_gradient_norm = tf.placeholder('float32', [], name='max_gradient_norm') # often set to a value like 5 or 1\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding(model):\n",
    "    with tf.variable_scope(\"embedding\", dtype='float32') as scope:\n",
    "        # Embedding\n",
    "        embedding_encoder = tf.get_variable(\"embedding_encoder\", [input_size+1, embedding_size])\n",
    "        embedding_decoder = tf.get_variable(\"embedding_decoder\", [input_size+1, embedding_size])\n",
    "        \n",
    "        # Look up embedding:\n",
    "        #   encoder_inputs: [max_time, batch_size]\n",
    "        #   encoder_emp_inp: [max_time, batch_size, embedding_size]\n",
    "        encoder_emb_inp = tf.nn.embedding_lookup(embedding_encoder, model.encoder_inputs)\n",
    "        decoder_emb_inp = tf.nn.embedding_lookup(embedding_decoder, model.decoder_inputs)\n",
    "        \n",
    "        model.embedding_encoder = embedding_encoder\n",
    "        model.embedding_decoder = embedding_decoder\n",
    "        model.encoder_emb_inp = encoder_emb_inp\n",
    "        model.decoder_emb_inp = decoder_emb_inp\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Encoder\n",
    "def encoder(model):\n",
    "    with tf.variable_scope(\"encoder\", dtype='float32') as scope:\n",
    "        # Build RNN cell\n",
    "        encoder_cell = tf.contrib.rnn.GRUCell(num_units)\n",
    "\n",
    "        # Run Dynamic RNN\n",
    "        #   encoder_outpus: [max_time, batch_size, num_units]\n",
    "        #   encoder_state: [batch_size, num_units]\n",
    "        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "            encoder_cell, model.encoder_emb_inp, dtype='float32',\n",
    "            sequence_length=model.source_sequence_lengths, time_major=True)\n",
    "        \n",
    "        model.encoder_outputs = encoder_outputs\n",
    "        model.encoder_state = encoder_state\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Decoder\n",
    "def decoder(model):\n",
    "    with tf.variable_scope(\"decoder\", dtype='float32') as scope:\n",
    "        \"\"\" Attention Mechanisms \"\"\"\n",
    "        # attention_states: [batch_size, max_time, num_units]\n",
    "        attention_states = tf.transpose(model.encoder_outputs, [1, 0, 2])\n",
    "\n",
    "        # Create an attention mechanism\n",
    "        attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "            num_units, attention_states, scale=True,\n",
    "            memory_sequence_length=model.source_sequence_lengths)\n",
    "\n",
    "        \n",
    "        decoder_cell = tf.contrib.rnn.GRUCell(num_units)\n",
    "\n",
    "        decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cell, attention_mechanism,\n",
    "            alignment_history=True,\n",
    "            attention_layer_size=num_units, name=\"attention\")\n",
    "\n",
    "        decoder_initial_state = decoder_cell.zero_state(tf.shape(model.decoder_emb_inp)[1], 'float32').clone(cell_state=model.encoder_state)\n",
    "        \"\"\"\"\"\"\n",
    "        # Helper\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            model.decoder_emb_inp, model.target_sequence_lengths, time_major=True)\n",
    "        # Decoder\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper, decoder_initial_state)\n",
    "        # Dynamic decoding\n",
    "        outputs, final_context_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder,\n",
    "            output_time_major=True,\n",
    "            swap_memory=True,\n",
    "            scope=scope)\n",
    "\n",
    "        #projection\n",
    "        output_layer = layers_core.Dense(input_size+1, use_bias=False, name=\"output_projection\")\n",
    "        logits = output_layer(outputs.rnn_output)\n",
    "        \n",
    "    model.logits = logits\n",
    "    model.decoder_cell = decoder_cell\n",
    "    model.decoder_initial_state = decoder_initial_state\n",
    "    model.output_layer = output_layer\n",
    "    model.final_context_state = final_context_state\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Loss & Gradient computation & optimization\n",
    "\n",
    "def optimizer(model):\n",
    "    curr_max_time = tf.shape(model.logits)[0]\n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=model.targets[:curr_max_time,:], logits=model.logits)\n",
    "    target_weights = tf.sequence_mask(model.target_sequence_lengths, curr_max_time, dtype=model.logits.dtype)\n",
    "\n",
    "    # When time_major is True\n",
    "    target_weights = tf.transpose(target_weights)\n",
    "\n",
    "    loss = tf.reduce_sum(crossent * target_weights) / tf.to_float(tf.shape(model.decoder_emb_inp)[1])\n",
    "\n",
    "    # Calculate and clip gradients\n",
    "    parameters = tf.trainable_variables()\n",
    "    gradients = tf.gradients(loss, parameters)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(gradients, model.max_gradient_norm)\n",
    "\n",
    "    # Optimization\n",
    "    optimizer = tf.train.GradientDescentOptimizer(model.learning_rate)\n",
    "    update_step = optimizer.apply_gradients(zip(clipped_gradients, parameters))\n",
    "    \n",
    "    model.loss = loss\n",
    "    model.update_step = update_step\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = initialization()\n",
    "    model = embedding(model)\n",
    "    model = encoder(model)\n",
    "    model = decoder(model)\n",
    "    model = optimizer(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Running training\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5999 7.627950.7781 9.77482\r"
     ]
    }
   ],
   "source": [
    "for i in range(6000):\n",
    "    \n",
    "    if i==0:\n",
    "        lr = 1.\n",
    "    elif i==3000:\n",
    "        lr = .5\n",
    "    elif i==4000:\n",
    "        lr = .25\n",
    "    elif i==5000:\n",
    "        lr = .125\n",
    "    \n",
    "    if np.random.rand() > 0.5:\n",
    "        seq_len = 10\n",
    "    else:\n",
    "        seq_len = 20\n",
    "        \n",
    "    x, y = next_batch(batch_size, seq_len, max_time, input_size)\n",
    "    feed_dict={model.learning_rate: lr,\n",
    "               model.max_gradient_norm: 1,\n",
    "               model.source_sequence_lengths: [seq_len+1]*batch_size,\n",
    "               model.target_sequence_lengths: [seq_len+1]*batch_size,\n",
    "               model.encoder_inputs: x,\n",
    "               model.targets: y}\n",
    "\n",
    "\n",
    "    _, l_val = sess.run([model.update_step, model.loss], feed_dict=feed_dict)\n",
    "    print(i, l_val, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Evaluating the network\n",
    "def evaluation(model):\n",
    "\n",
    "    model.maximum_iterations = tf.round(tf.reduce_max(model.source_sequence_lengths) * 2)\n",
    "\n",
    "    with tf.variable_scope('decoder', reuse=True) as scope:\n",
    "    # Dynamic decoding\n",
    "        # Helper\n",
    "        helper_eval = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            model.embedding_decoder, tf.fill([tf.shape(model.decoder_emb_inp)[1]], 0),\n",
    "            0)\n",
    "        # Decoder\n",
    "        decoder_eval = tf.contrib.seq2seq.BasicDecoder(\n",
    "            model.decoder_cell, helper_eval, model.decoder_initial_state,\n",
    "            output_layer=model.output_layer)\n",
    "\n",
    "        outputs_eval, final_context_state_eval, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder_eval, maximum_iterations=model.maximum_iterations,\n",
    "            swap_memory=True, scope=scope)\n",
    "\n",
    "        model.logits_eval = outputs_eval.rnn_output\n",
    "        \n",
    "    curr_max_time = tf.shape(model.logits)[0]\n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=model.targets[:curr_max_time,:], logits=model.logits)\n",
    "    target_weights = tf.sequence_mask(model.target_sequence_lengths, curr_max_time, dtype=model.logits.dtype)\n",
    "\n",
    "    # When time_major is True\n",
    "    target_weights = tf.transpose(target_weights)\n",
    "\n",
    "    loss = tf.reduce_sum(crossent * target_weights) / tf.to_float(tf.shape(model.decoder_emb_inp)[1])\n",
    "    \n",
    "    model.loss_eval = loss\n",
    "    model.final_context_state_eval = final_context_state_eval\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_eval = evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attention_images = (model.final_context_state_eval.alignment_history.stack())\n",
    "# Reshape to (batch, src_seq_len, tgt_seq_len,1)\n",
    "attention_images = tf.expand_dims(tf.transpose(attention_images, [1, 2, 0]), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prettify_stn(stn):\n",
    "    ret = []\n",
    "    for w in stn:\n",
    "        if w == 0:\n",
    "            break\n",
    "        else:\n",
    "            ret.append(w)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f669dde96a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0EVEksT/B+4KBSeDJ7jyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f66bc30a748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f669de9ad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = 15\n",
    "x, y = next_batch(batch_size, seq_len, max_time, input_size)\n",
    "feed_dict={model.learning_rate: lr,\n",
    "           model.max_gradient_norm: 1,\n",
    "           model.source_sequence_lengths: [seq_len+1]*batch_size,\n",
    "           model.target_sequence_lengths: [seq_len+1]*batch_size,\n",
    "           model.encoder_inputs: x,\n",
    "           model.targets: y}\n",
    "\n",
    "d = prettify_stn(feed_dict[model.encoder_inputs][:,0])\n",
    "\n",
    "plt.plot(np.argmax(sess.run(model.logits_eval, feed_dict),2)[0][:len(d)])\n",
    "plt.plot(np.sort(d))\n",
    "\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.matshow(sess.run(attention_images, feed_dict)[0][:,:,0][:len(d),:len(d)], cmap='bone')\n",
    "ax2.matshow(np.eye(len(d))[np.argsort(d)].T, cmap='bone')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
