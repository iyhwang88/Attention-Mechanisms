{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Seq2Seq Model with Attention in Sorting Problems\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dummy(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "input_size = 30\n",
    "max_time = 30\n",
    "embedding_size = 10\n",
    "num_units = embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(batch_size, seq_len, max_time, input_size=10):\n",
    "    data = np.zeros((batch_size, max_time), dtype='int32')\n",
    "    data[:,:seq_len] = np.random.randint(1, input_size+1, (batch_size, seq_len))\n",
    "    labels = np.zeros((batch_size, max_time), dtype='int32')\n",
    "    labels[:,:seq_len] = np.sort(data[:, :seq_len])\n",
    "    \n",
    "    # time major\n",
    "    return data.T, labels.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialization():\n",
    "    model = Dummy()\n",
    "    model.encoder_inputs = tf.placeholder('int32', [max_time, None], name='encoder_inputs')\n",
    "    model.targets = tf.placeholder('int32', [max_time, None], name='target')\n",
    "    model.decoder_inputs = tf.concat([tf.fill([1, tf.shape(model.targets)[1]], 0), model.targets[:-1,:]], 0)\n",
    "    \n",
    "    model.source_sequence_lengths = tf.placeholder('int32', [None], name='source_sequence_lengths')\n",
    "    model.target_sequence_lengths = tf.placeholder('int32', [None], name='target_sequence_lengths')\n",
    "    \n",
    "    model.learning_rate = tf.placeholder('float32', [], name='learning_rate')\n",
    "    model.max_gradient_norm = tf.placeholder('float32', [], name='max_gradient_norm') # often set to a value like 5 or 1\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding(model):\n",
    "    with tf.variable_scope(\"embedding\", dtype='float32') as scope:\n",
    "        # Embedding\n",
    "        embedding_encoder = tf.get_variable(\"embedding_encoder\", [input_size+1, embedding_size])\n",
    "        embedding_decoder = tf.get_variable(\"embedding_decoder\", [input_size+1, embedding_size])\n",
    "        \n",
    "        # Look up embedding:\n",
    "        #   encoder_inputs: [max_time, batch_size]\n",
    "        #   encoder_emp_inp: [max_time, batch_size, embedding_size]\n",
    "        encoder_emb_inp = tf.nn.embedding_lookup(embedding_encoder, model.encoder_inputs)\n",
    "        decoder_emb_inp = tf.nn.embedding_lookup(embedding_decoder, model.decoder_inputs)\n",
    "        \n",
    "        model.embedding_encoder = embedding_encoder\n",
    "        model.embedding_decoder = embedding_decoder\n",
    "        model.encoder_emb_inp = encoder_emb_inp\n",
    "        model.decoder_emb_inp = decoder_emb_inp\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Encoder\n",
    "def encoder(model):\n",
    "    with tf.variable_scope(\"encoder\", dtype='float32') as scope:\n",
    "        # Build RNN cell\n",
    "        encoder_cell = tf.contrib.rnn.GRUCell(num_units)\n",
    "\n",
    "        # Run Dynamic RNN\n",
    "        #   encoder_outpus: [max_time, batch_size, num_units]\n",
    "        #   encoder_state: [batch_size, num_units]\n",
    "        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "            encoder_cell, model.encoder_emb_inp, dtype='float32',\n",
    "            sequence_length=model.source_sequence_lengths, time_major=True)\n",
    "        \n",
    "        model.encoder_outputs = encoder_outputs\n",
    "        model.encoder_state = encoder_state\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "original source code: https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py#L361-L469\n",
    "\"\"\"\n",
    "from tensorflow.contrib.seq2seq.python.ops.attention_wrapper import _BaseAttentionMechanism\n",
    "\n",
    "class BahdanauAttention(_BaseAttentionMechanism):\n",
    "    def __init__(self, num_units, memory, memory_sequence_length, name=\"BahdanauAttention\"):\n",
    "        super(BahdanauAttention, self).__init__(\n",
    "            query_layer=layers_core.Dense(num_units, name=\"query_layer\", use_bias=False),\n",
    "            memory_layer=layers_core.Dense(num_units, name=\"memory_layer\", use_bias=False),\n",
    "            memory=memory,\n",
    "            probability_fn=lambda score, _: tf.nn.softmax(score),\n",
    "            memory_sequence_length=memory_sequence_length,\n",
    "            score_mask_value=float(\"-inf\"),\n",
    "            name=name)\n",
    "        \n",
    "        self._num_units = num_units\n",
    "        self._name = name\n",
    "\n",
    "    def __call__(self, query, previous_alignments):\n",
    "        with tf.variable_scope(None, \"bahdanau_attention\"):\n",
    "            processed_query = self.query_layer(query)\n",
    "            dtype = processed_query.dtype\n",
    "            # Reshape from [batch_size, ...] to [batch_size, 1, ...] for broadcasting.\n",
    "            processed_query = tf.expand_dims(processed_query, 1)\n",
    "            keys = self._keys\n",
    "            v = tf.get_variable(\"attention_v\", [self._num_units], dtype=dtype)\n",
    "            score = tf.reduce_sum(v * tf.tanh(keys + processed_query), [2])\n",
    "\n",
    "        alignments = self._probability_fn(score, previous_alignments)\n",
    "        return alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Decoder\n",
    "def decoder(model):\n",
    "    with tf.variable_scope(\"decoder\", dtype='float32') as scope:\n",
    "        \"\"\" Attention Mechanisms \"\"\"\n",
    "        # attention_states: [batch_size, max_time, num_units]\n",
    "        attention_states = tf.transpose(model.encoder_outputs, [1, 0, 2])\n",
    "\n",
    "        # Create an attention mechanism\n",
    "        \"\"\"\n",
    "        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "            num_units, attention_states,\n",
    "            memory_sequence_length=model.source_sequence_lengths)\n",
    "        \"\"\"\n",
    "        attention_mechanism = BahdanauAttention(num_units, attention_states, model.source_sequence_lengths)\n",
    "        \n",
    "        decoder_cell = tf.contrib.rnn.GRUCell(num_units)\n",
    "\n",
    "        decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            decoder_cell, attention_mechanism,\n",
    "            alignment_history=True,\n",
    "            attention_layer_size=num_units, name=\"attention\")\n",
    "\n",
    "        decoder_initial_state = decoder_cell.zero_state(tf.shape(model.decoder_emb_inp)[1], 'float32').clone(cell_state=model.encoder_state)\n",
    "        \n",
    "        # Helper\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            model.decoder_emb_inp, model.target_sequence_lengths, time_major=True)\n",
    "        # Decoder\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper, decoder_initial_state)\n",
    "        # Dynamic decoding\n",
    "        outputs, final_context_state, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder,\n",
    "            output_time_major=True,\n",
    "            swap_memory=True,\n",
    "            scope=scope)\n",
    "\n",
    "        #projection\n",
    "        output_layer = layers_core.Dense(input_size+1, use_bias=False, name=\"output_projection\")\n",
    "        logits = output_layer(outputs.rnn_output)\n",
    "        \n",
    "    model.logits = logits\n",
    "    model.decoder_cell = decoder_cell\n",
    "    model.decoder_initial_state = decoder_initial_state\n",
    "    model.output_layer = output_layer\n",
    "    model.final_context_state = final_context_state\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Loss & Gradient computation & optimization\n",
    "\n",
    "def optimizer(model):\n",
    "    curr_max_time = tf.shape(model.logits)[0]\n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=model.targets[:curr_max_time,:], logits=model.logits)\n",
    "    target_weights = tf.sequence_mask(model.target_sequence_lengths, curr_max_time, dtype=model.logits.dtype)\n",
    "\n",
    "    # When time_major is True\n",
    "    target_weights = tf.transpose(target_weights)\n",
    "\n",
    "    loss = tf.reduce_sum(crossent * target_weights) / tf.to_float(tf.shape(model.decoder_emb_inp)[1])\n",
    "\n",
    "    # Calculate and clip gradients\n",
    "    parameters = tf.trainable_variables()\n",
    "    gradients = tf.gradients(loss, parameters)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(gradients, model.max_gradient_norm)\n",
    "\n",
    "    # Optimization\n",
    "    optimizer = tf.train.GradientDescentOptimizer(model.learning_rate)\n",
    "    update_step = optimizer.apply_gradients(zip(clipped_gradients, parameters))\n",
    "    \n",
    "    model.loss = loss\n",
    "    model.update_step = update_step\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = initialization()\n",
    "    model = embedding(model)\n",
    "    model = encoder(model)\n",
    "    model = decoder(model)\n",
    "    model = optimizer(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Running training\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(6000):\n",
    "    \n",
    "    if i==0:\n",
    "        lr = 1.\n",
    "    elif i==3000:\n",
    "        lr = .5\n",
    "    elif i==4000:\n",
    "        lr = .25\n",
    "    elif i==5000:\n",
    "        lr = .125\n",
    "    \n",
    "    if np.random.rand() > 0.5:\n",
    "        seq_len = 10\n",
    "    else:\n",
    "        seq_len = 20\n",
    "        \n",
    "    x, y = next_batch(batch_size, seq_len, max_time, input_size)\n",
    "    feed_dict={model.learning_rate: lr,\n",
    "               model.max_gradient_norm: 1,\n",
    "               model.source_sequence_lengths: [seq_len+1]*batch_size,\n",
    "               model.target_sequence_lengths: [seq_len+1]*batch_size,\n",
    "               model.encoder_inputs: x,\n",
    "               model.targets: y}\n",
    "\n",
    "\n",
    "    _, l_val = sess.run([model.update_step, model.loss], feed_dict=feed_dict)\n",
    "    print(i, l_val, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Evaluating the network\n",
    "def evaluation(model):\n",
    "\n",
    "    model.maximum_iterations = tf.round(tf.reduce_max(model.source_sequence_lengths) * 2)\n",
    "\n",
    "    with tf.variable_scope('decoder', reuse=True) as scope:\n",
    "    # Dynamic decoding\n",
    "        # Helper\n",
    "        helper_eval = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            model.embedding_decoder, tf.fill([tf.shape(model.decoder_emb_inp)[1]], 0),\n",
    "            0)\n",
    "        # Decoder\n",
    "        decoder_eval = tf.contrib.seq2seq.BasicDecoder(\n",
    "            model.decoder_cell, helper_eval, model.decoder_initial_state,\n",
    "            output_layer=model.output_layer)\n",
    "        \"\"\"\n",
    "    decoder_eval = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "          cell=model.decoder_cell,\n",
    "          embedding=model.embedding_decoder,\n",
    "          start_tokens=tf.fill([tf.shape(model.decoder_emb_inp)[1]], 0),\n",
    "          end_token=0,\n",
    "          initial_state=model.decoder_initial_state,\n",
    "          beam_width=12,\n",
    "          output_layer=model.output_layer,\n",
    "          length_penalty_weight=0.)\n",
    "        \"\"\"\n",
    "        outputs_eval, final_context_state_eval, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder_eval, maximum_iterations=model.maximum_iterations,\n",
    "            swap_memory=True, scope=scope)\n",
    "\n",
    "        model.logits_eval = outputs_eval.rnn_output\n",
    "        \n",
    "    curr_max_time = tf.shape(model.logits)[0]\n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=model.targets[:curr_max_time,:], logits=model.logits)\n",
    "    target_weights = tf.sequence_mask(model.target_sequence_lengths, curr_max_time, dtype=model.logits.dtype)\n",
    "\n",
    "    # When time_major is True\n",
    "    target_weights = tf.transpose(target_weights)\n",
    "\n",
    "    loss = tf.reduce_sum(crossent * target_weights) / tf.to_float(tf.shape(model.decoder_emb_inp)[1])\n",
    "    \n",
    "    model.loss_eval = loss\n",
    "    model.final_context_state_eval = final_context_state_eval\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_eval = evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attention_images = (model.final_context_state_eval.alignment_history.stack())\n",
    "# Reshape to (batch, src_seq_len, tgt_seq_len,1)\n",
    "attention_images = tf.expand_dims(tf.transpose(attention_images, [1, 2, 0]), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prettify_stn(stn):\n",
    "    ret = []\n",
    "    for w in stn:\n",
    "        if w == 0:\n",
    "            break\n",
    "        else:\n",
    "            ret.append(w)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc3ef2b9b70>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJRQoUuIhIlVOgiIlFChS4iEiX+H7VpGm4+JaECAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3ef3e3748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3ef3749e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = 15\n",
    "x, y = next_batch(batch_size, seq_len, max_time, input_size)\n",
    "feed_dict={model.learning_rate: lr,\n",
    "           model.max_gradient_norm: 1,\n",
    "           model.source_sequence_lengths: [seq_len+1]*batch_size,\n",
    "           model.target_sequence_lengths: [seq_len+1]*batch_size,\n",
    "           model.encoder_inputs: x,\n",
    "           model.targets: y}\n",
    "\n",
    "d = prettify_stn(feed_dict[model.encoder_inputs][:,0])\n",
    "\n",
    "plt.plot(np.argmax(sess.run(model.logits_eval, feed_dict),2)[0][:len(d)])\n",
    "plt.plot(np.sort(d))\n",
    "\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.matshow(sess.run(attention_images, feed_dict)[0][:,:,0][:len(d),:len(d)], cmap='bone')\n",
    "ax2.matshow(np.eye(len(d))[np.argsort(d)].T, cmap='bone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
